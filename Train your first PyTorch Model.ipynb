{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4532039,"sourceType":"datasetVersion","datasetId":2579480}],"dockerImageVersionId":30763,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Train your first PyTorch Model - card classification","metadata":{}},{"cell_type":"markdown","source":"1. Pytorch Dtaset\n2. Pytorch Model\n3. Pytorch Training loop\n\nAlmost every pytorch model training pipelline meet this paradigm","metadata":{}},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nimport timm\nimport torchvision\n\nfrom tqdm.notebook import tqdm  \n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport sys \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Versions","metadata":{}},{"cell_type":"code","source":"print('System Version: ', sys.version)\nprint('PyTorch Version: ', torch.__version__)\nprint('TorchVision Version', torchvision.__version__)\nprint('Numpy version',np.__version__)\nprint('Pandas version',pd.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 1: Pytorch Dataset and DataLoader\nwould you learn how to bake a cake","metadata":{}},{"cell_type":"code","source":"class PlayingCardDataset(Dataset):\n    \n    def __init__(self, data_dir, transform=None):\n        self.data = ImageFolder(data_dir, transform=transform)\n        \n    \n    def __len__(self):\n        return len(self.data)\n    \n    \n    def __getitem__(self,idx):\n        return self.data[idx]\n    \n    @property\n    def classses(self):\n        return self.data.classes \n    \n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = PlayingCardDataset(\n                data_dir='/kaggle/input/cards-image-datasetclassification/train'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, label = dataset[5000]\nimage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get a dictionary associating target vvalues with folder  names\n\ndata_dir = '/kaggle/input/cards-image-datasetclassification/train'\ntarget_to_class = {v: k for k, v in ImageFolder(data_dir).class_to_idx.items()}\nprint(target_to_class)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup Datasets","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((128,128)),\n    transforms.ToTensor(), \n])\n\ndata_dir = '/kaggle/input/cards-image-datasetclassification/train'\ndataset = PlayingCardDataset(data_dir, transform)\n\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, label = dataset[100]\nimage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## iterate over dataset\n\nfor image, label in dataset:\n    \n    break ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data loaders\n* batching our dataset","metadata":{}},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for images, labels in dataloader:\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((128,128)),\n    transforms.ToTensor(), \n])\n\n \n\ntrain_folder  = '/kaggle/input/cards-image-datasetclassification/train'\ntest_folder = '/kaggle/input/cards-image-datasetclassification/test'\nval_folder = '/kaggle/input/cards-image-datasetclassification/valid'\n\n\ntrain_dataset = PlayingCardDataset(train_folder, transform=transform)\ntest_dataset = PlayingCardDataset(test_folder, transform=transform)\nvalid_dataset = PlayingCardDataset(val_folder, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\nvalid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: Pytorch Model\n\n* we could create the model from scratch defining each leayer\n* TIMM","metadata":{}},{"cell_type":"code","source":"class SimpleCardClassifier(nn.Module):\n    \n    def __init__(self, num_classes=53):\n        super(SimpleCardClassifier, self).__init__()\n        # where we define all the parts of the model\n        self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n        \n        enet_out_size = 1280 \n        #make a classifier\n        self.classifier = nn.Linear(enet_out_size, num_classes)\n        \n        \n        \n    def forward(self,x):\n        # connect these parts and return the output\n        x = self.features(x)\n        output = self.classifier(x)\n        return output\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SimpleCardClassifier(num_classes=53)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(str(model)[:500])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_out = model(images)\nexample_out.shape  ## [batch size, num classes]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3 : Training loop\n\n* terms: \n    * Epoch : one run through the entire training dataset\n    * step: one batch of data as defined in our dataloader\n* This loop is one you will become familiar with when training models, you load in data to the model in batches - then calculate the loss and perform backpropagation.  There are packages that package this for you, but its good to have at least written it once to understand how itworks.\n\n* Two things to select:\n    * optimizer, adam is the best place to start for most tasks\n    * loss function : what the model will optimize for","metadata":{}},{"cell_type":"code","source":"# loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Optimizer function\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion(example_out, labels\n         )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs=5\ntrain_loss, val_loss = [], []\n\nmodel = SimpleCardClassifier(num_classes=53)\nmodel.to(device)\n\nfor epoch in range(num_epochs):\n    # set the model to train\n    model.train()\n    running_loss = 0.0 \n    for images, labels in tqdm(train_loader, desc='training loop'):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n    train_los =  running_loss / len(train_loader.dataset)\n    train_loss.append(train_los)\n    \n    # validation phase\n    model.eval()\n    running_loss = 0.0 \n    with torch.no_grad():\n        for images, labels in tqdm(valid_loader, desc='validation loop'):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * images.size(0)\n        val_los = running_loss / len(valid_loader.dataset)\n        val_loss.append(val_los)\n        \n    print(f'Epoch {epoch+1}/{num_epochs} - Train loss: {train_los}, validationloss : {val_los}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}